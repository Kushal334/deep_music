{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic multilayer LSTM-RNN \n",
    "\n",
    "To increase the power of our network we can add several layers of LSTM cells using the *MultiRNNCell* function, resulting in a *deep* recurrent neural network. Further, we will add dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Global configuration parameters\n",
    "n_epochs = 20\n",
    "total_series_length = 50000\n",
    "truncated_backprop_steps = 15\n",
    "echo_step = 3 # number of steps the input is shifted to the right\n",
    "batch_size = 5\n",
    "eta = 0.001 # learning rate\n",
    "n_batches = total_series_length// batch_size//truncated_backprop_steps\n",
    "\n",
    "# Network parameters\n",
    "n_hidden = 10 # number of hidden units in each LSTM layer\n",
    "n_layers = 2 \n",
    "inp_drop = 1 # dropout input keep probability\n",
    "out_drop = 1 # dropout output keep probability\n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data\n",
    "\n",
    "Up to now, our complete training data had the size (5, 10000). Although we will keep these dimensions and also the dimension of the X_placeholder variabe, we will add another dimension to the input when feeding it into the RNN. Before, the batch size was (5,15), i.e. (batch_size, truncated_backprop_steps). Now, for the dynamic rnn the batch size will be (5,15,1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateData():\n",
    "    \"\"\"\n",
    "    Generates training data. The input data is simply a vector of random\n",
    "    numbers with n_classes classes. The target output is the input shifted \n",
    "    by \"echo_steps\" steps to the right.\n",
    "    \n",
    "    Returns:\n",
    "        x: numpy array of shape (batch_size,-1) filled with random values\n",
    "        in the range (n_classes)\n",
    "        \n",
    "        y: numpy array of shape (batch_size, -1), x shifted \"echo_step\" to \n",
    "        the right\n",
    "    \"\"\"\n",
    "\n",
    "    x = np.array(np.random.choice(n_classes, total_series_length))\n",
    "    y = np.roll(x, echo_step)\n",
    "    y[0:echo_step] = 0\n",
    "\n",
    "    x = x.reshape((batch_size, -1))\n",
    "    y = y.reshape((batch_size, -1))\n",
    "\n",
    "    return(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network architecture and forward pass\n",
    "\n",
    "As mentioned before, the shape of the input batches is now (batch_size, truncated_backprop_steps, input_size). Our X_placeholder variable can stay the same but we will insert a dimension of 1 when feeding it into tf.nn.dynamic_rnn. This is done using the function [tf.expand_dims](https://www.tensorflow.org/api_docs/python/tf/expand_dims)\n",
    "\n",
    "To create multiple layers we call the MultiRNNCell function that takes a list of RNN cells as an input and wraps them into a single cell. \n",
    "To further use dropout with MultiRNNCell we wrap the base LSTM cell with dropout. This ensures that dropout is part of each cell passed into the MultiRNNCell function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_placeholder = tf.placeholder(tf.float32, shape=[batch_size, truncated_backprop_steps])\n",
    "y_placeholder = tf.placeholder(tf.int32, shape=[batch_size, truncated_backprop_steps])\n",
    "\n",
    "# Since we are using several hidden layers, we would have to define a cell \n",
    "# state and hidden state for every layer. Therefore, we save the state of \n",
    "# the whole network in a tensor. For every layer and every sample in the \n",
    "# batch we will have a cell state and a hidden state of size n_hidden\n",
    "init_state = tf.placeholder(tf.float32, [n_layers, 2, batch_size, n_hidden])\n",
    "\n",
    "# Since the input to the MultiRNN cell must be a tuple of LSTM tuples, we\n",
    "# unpack the state tensor.\n",
    "# First, we unstack the tensor into one 3D tensor per layer \n",
    "state_per_layer_list = tf.unstack(init_state, axis=0)\n",
    "\n",
    "# Then, we create an LSTM tuple for each layer and put all of the LSTM tuples\n",
    "# into a tuple\n",
    "rnn_tuple_state = tuple(\n",
    "    [tf.contrib.rnn.LSTMStateTuple(state_per_layer_list[idx][0], state_per_layer_list[idx][1])\n",
    "     for idx in range(n_layers)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For each initialized LSTM cell we need to specify how many hidden\n",
    "# units the cell should have.\n",
    "cell = tf.contrib.rnn.LSTMCell(num_units=n_hidden)\n",
    "\n",
    "# Add dropout\n",
    "cell = tf.contrib.rnn.DropoutWrapper(cell, \n",
    "                                     input_keep_prob=inp_drop, \n",
    "                                     output_keep_prob=out_drop)\n",
    "\n",
    "# Create multiple layers using the MultiRNNCell function\n",
    "cell = tf.contrib.rnn.MultiRNNCell([cell]*n_layers)\n",
    "\n",
    "# Create a zero-filled state tensor\n",
    "#init_state = cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "# Create a recurrent neural network specified by \"cell\", i.e. unroll the\n",
    "# network.\n",
    "# Returns a list of all previous RNN hidden states and the final states.\n",
    "# final_state is now contains three LSTMStateTuple that contain both the \n",
    "# final hidden and the cell state of the respective layer.\n",
    "\n",
    "outputs, final_state = tf.nn.dynamic_rnn(cell, tf.expand_dims(X_placeholder,-1), initial_state=rnn_tuple_state)\n",
    "\n",
    "# Reshape the outputs and targets such that the logits can be computed \n",
    "# using a single matrix multiplication\n",
    "temp = tf.reshape(outputs, [-1, n_hidden])\n",
    "y_temp = tf.reshape(y_placeholder, [-1])\n",
    "\n",
    "# The output of the network is a one-hot encoded vector of predictions.\n",
    "# When also transforming the target labels into a one-hot encoding (as done\n",
    "# below), we have to change the loss computation into \n",
    "# \"tf.nn.softmax_cross_entropy_with_logits\"\n",
    "#y_temp_one_hot = tf.one_hot(y_temp, n_classes)\n",
    "\n",
    "V = tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "c = tf.Variable(tf.random_normal([n_classes]))\n",
    "\n",
    "logits = tf.matmul(temp,V)+c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network output and loss function\n",
    "\n",
    "The predictions of the RNN and the loss are computed in the same way as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_temp_one_hot,\n",
    "#                                                              logits=l))\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_temp,\n",
    "                                                             logits=logits))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=eta).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  0\n",
      "Step:  0 Loss:  0.689573\n",
      "Step:  100 Loss:  0.668396\n",
      "Step:  200 Loss:  0.568883\n",
      "Step:  300 Loss:  0.500575\n",
      "Step:  400 Loss:  0.434712\n",
      "Step:  500 Loss:  0.476389\n",
      "Step:  600 Loss:  0.13591\n",
      "\n",
      "Epoch:  1\n",
      "Step:  0 Loss:  0.583608\n",
      "Step:  100 Loss:  0.0959407\n",
      "Step:  200 Loss:  0.0188441\n",
      "Step:  300 Loss:  0.0151491\n",
      "Step:  400 Loss:  0.00912536\n",
      "Step:  500 Loss:  0.00844134\n",
      "Step:  600 Loss:  0.00598813\n",
      "\n",
      "Epoch:  2\n",
      "Step:  0 Loss:  0.398901\n",
      "Step:  100 Loss:  0.00490044\n",
      "Step:  200 Loss:  0.0029903\n",
      "Step:  300 Loss:  0.00295215\n",
      "Step:  400 Loss:  0.00179693\n",
      "Step:  500 Loss:  0.00205465\n",
      "Step:  600 Loss:  0.00157947\n",
      "\n",
      "Epoch:  3\n",
      "Step:  0 Loss:  0.450208\n",
      "Step:  100 Loss:  0.0014779\n",
      "Step:  200 Loss:  0.00123453\n",
      "Step:  300 Loss:  0.00108328\n",
      "Step:  400 Loss:  0.00108951\n",
      "Step:  500 Loss:  0.000942172\n",
      "Step:  600 Loss:  0.000953409\n",
      "\n",
      "Epoch:  4\n",
      "Step:  0 Loss:  0.269758\n",
      "Step:  100 Loss:  0.000723037\n",
      "Step:  200 Loss:  0.00077895\n",
      "Step:  300 Loss:  0.000550912\n",
      "Step:  400 Loss:  0.000545713\n",
      "Step:  500 Loss:  0.000600805\n",
      "Step:  600 Loss:  0.000545511\n",
      "\n",
      "Epoch:  5\n",
      "Step:  0 Loss:  0.158962\n",
      "Step:  100 Loss:  0.00044606\n",
      "Step:  200 Loss:  0.000377006\n",
      "Step:  300 Loss:  0.000356041\n",
      "Step:  400 Loss:  0.000303232\n",
      "Step:  500 Loss:  0.000379601\n",
      "Step:  600 Loss:  0.000285785\n",
      "\n",
      "Epoch:  6\n",
      "Step:  0 Loss:  0.148983\n",
      "Step:  100 Loss:  0.00026073\n",
      "Step:  200 Loss:  0.000268386\n",
      "Step:  300 Loss:  0.000222462\n",
      "Step:  400 Loss:  0.0001813\n",
      "Step:  500 Loss:  0.000201889\n",
      "Step:  600 Loss:  0.000228775\n",
      "\n",
      "Epoch:  7\n",
      "Step:  0 Loss:  0.25628\n",
      "Step:  100 Loss:  0.000174289\n",
      "Step:  200 Loss:  0.000193179\n",
      "Step:  300 Loss:  0.00017828\n",
      "Step:  400 Loss:  0.000145314\n",
      "Step:  500 Loss:  0.00013796\n",
      "Step:  600 Loss:  0.000133769\n",
      "\n",
      "Epoch:  8\n",
      "Step:  0 Loss:  0.166355\n",
      "Step:  100 Loss:  0.000112777\n",
      "Step:  200 Loss:  0.000128338\n",
      "Step:  300 Loss:  0.000103803\n",
      "Step:  400 Loss:  9.12455e-05\n",
      "Step:  500 Loss:  9.72991e-05\n",
      "Step:  600 Loss:  9.29866e-05\n",
      "\n",
      "Epoch:  9\n",
      "Step:  0 Loss:  0.134407\n",
      "Step:  100 Loss:  8.56385e-05\n",
      "Step:  200 Loss:  7.80211e-05\n",
      "Step:  300 Loss:  8.46823e-05\n",
      "Step:  400 Loss:  5.35097e-05\n",
      "Step:  500 Loss:  5.92538e-05\n",
      "Step:  600 Loss:  6.90457e-05\n",
      "\n",
      "Epoch:  10\n",
      "Step:  0 Loss:  0.140861\n",
      "Step:  100 Loss:  9.07916e-05\n",
      "Step:  200 Loss:  6.31975e-05\n",
      "Step:  300 Loss:  7.55463e-05\n",
      "Step:  400 Loss:  5.61722e-05\n",
      "Step:  500 Loss:  5.88396e-05\n",
      "Step:  600 Loss:  4.57258e-05\n",
      "\n",
      "Epoch:  11\n",
      "Step:  0 Loss:  0.157605\n",
      "Step:  100 Loss:  4.99369e-05\n",
      "Step:  200 Loss:  4.92138e-05\n",
      "Step:  300 Loss:  4.00401e-05\n",
      "Step:  400 Loss:  3.21044e-05\n",
      "Step:  500 Loss:  4.18025e-05\n",
      "Step:  600 Loss:  3.48175e-05\n",
      "\n",
      "Epoch:  12\n",
      "Step:  0 Loss:  0.164609\n",
      "Step:  100 Loss:  3.68853e-05\n",
      "Step:  200 Loss:  3.11031e-05\n",
      "Step:  300 Loss:  2.8126e-05\n",
      "Step:  400 Loss:  2.99508e-05\n",
      "Step:  500 Loss:  3.04769e-05\n",
      "Step:  600 Loss:  2.76589e-05\n",
      "\n",
      "Epoch:  13\n",
      "Step:  0 Loss:  0.160948\n",
      "Step:  100 Loss:  2.34852e-05\n",
      "Step:  200 Loss:  2.54689e-05\n",
      "Step:  300 Loss:  2.48601e-05\n",
      "Step:  400 Loss:  2.41385e-05\n",
      "Step:  500 Loss:  1.60071e-05\n",
      "Step:  600 Loss:  2.25111e-05\n",
      "\n",
      "Epoch:  14\n",
      "Step:  0 Loss:  0.237445\n",
      "Step:  100 Loss:  4.04249e-05\n",
      "Step:  200 Loss:  3.69258e-05\n",
      "Step:  300 Loss:  3.24213e-05\n",
      "Step:  400 Loss:  3.05461e-05\n",
      "Step:  500 Loss:  2.80592e-05\n",
      "Step:  600 Loss:  1.80114e-05\n",
      "\n",
      "Epoch:  15\n",
      "Step:  0 Loss:  0.147566\n",
      "Step:  100 Loss:  2.44404e-05\n",
      "Step:  200 Loss:  1.78461e-05\n",
      "Step:  300 Loss:  1.8798e-05\n",
      "Step:  400 Loss:  1.66254e-05\n",
      "Step:  500 Loss:  1.56256e-05\n",
      "Step:  600 Loss:  1.44209e-05\n",
      "\n",
      "Epoch:  16\n",
      "Step:  0 Loss:  0.148131\n",
      "Step:  100 Loss:  1.64426e-05\n",
      "Step:  200 Loss:  1.53507e-05\n",
      "Step:  300 Loss:  1.47499e-05\n",
      "Step:  400 Loss:  1.18938e-05\n",
      "Step:  500 Loss:  1.29078e-05\n",
      "Step:  600 Loss:  1.18254e-05\n",
      "\n",
      "Epoch:  17\n",
      "Step:  0 Loss:  0.16032\n",
      "Step:  100 Loss:  1.17729e-05\n",
      "Step:  200 Loss:  1.19605e-05\n",
      "Step:  300 Loss:  1.11515e-05\n",
      "Step:  400 Loss:  9.54777e-06\n",
      "Step:  500 Loss:  1.08765e-05\n",
      "Step:  600 Loss:  9.86727e-06\n",
      "\n",
      "Epoch:  18\n",
      "Step:  0 Loss:  0.156439\n",
      "Step:  100 Loss:  1.20876e-05\n",
      "Step:  200 Loss:  1.03536e-05\n",
      "Step:  300 Loss:  1.08081e-05\n",
      "Step:  400 Loss:  9.62407e-06\n",
      "Step:  500 Loss:  7.97425e-06\n",
      "Step:  600 Loss:  7.96312e-06\n",
      "\n",
      "Epoch:  19\n",
      "Step:  0 Loss:  0.119097\n",
      "Step:  100 Loss:  1.11372e-05\n",
      "Step:  200 Loss:  8.89767e-06\n",
      "Step:  300 Loss:  9.63042e-06\n",
      "Step:  400 Loss:  1.11435e-05\n",
      "Step:  500 Loss:  9.95943e-06\n",
      "Step:  600 Loss:  8.46538e-06\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    training_losses = []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"\")\n",
    "        print(\"Epoch: \", epoch)\n",
    "        \n",
    "        X_data, y_data = generateData()\n",
    "        _current_state = np.zeros((n_layers, 2, batch_size, n_hidden))\n",
    "        \n",
    "        for batch in range(n_batches):\n",
    "        \n",
    "            start_idx = batch*truncated_backprop_steps\n",
    "            end_idx = start_idx+truncated_backprop_steps\n",
    "            \n",
    "            batch_x = X_data[:, start_idx:end_idx]\n",
    "            batch_y = y_data[:, start_idx:end_idx]\n",
    "\n",
    "            _total_loss, _optimizer, _current_state = sess.run(\n",
    "                [loss, optimizer, final_state],\n",
    "                feed_dict={\n",
    "                    X_placeholder: batch_x,\n",
    "                    y_placeholder:batch_y,\n",
    "                    init_state: _current_state})\n",
    "            \n",
    "            training_losses.append(_total_loss)\n",
    "            \n",
    "            if batch%100 == 0:\n",
    "                print(\"Step: \", batch, \"Loss: \", _total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl8AAAHgCAYAAACbywggAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0a4d6b3780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,8));\n",
    "plt.plot(training_losses);\n",
    "plt.xlabel('Number of training iterations');\n",
    "plt.ylabel('Error');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
